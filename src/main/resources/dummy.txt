import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.JoinWindows;
import org.apache.kafka.streams.kstream.Materialized;
import org.apache.kafka.streams.kstream.Serialized;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.kstream.ValueJoiner;
import org.apache.kafka.streams.kstream.ValueMapper;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafkaStreams;
import org.springframework.kafka.config.KafkaStreamsConfiguration;
import org.springframework.kafka.core.StreamsBuilderFactoryBean;
import org.springframework.kafka.core.StreamsBuilderFactoryBeanConfigurer;

import java.time.Duration;
import java.util.HashMap;
import java.util.Map;

@Configuration
@EnableKafkaStreams
public class KafkaStreamsConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Value("${spring.kafka.streams.application-id}")
    private String applicationId;

    @Value("${spring.kafka.streams.properties.schema.registry.url}")
    private String schemaRegistryUrl;

    @Value("${spring.kafka.topic1.group-id}")
    private String groupIdTopic1;

    @Value("${spring.kafka.topic2.group-id}")
    private String groupIdTopic2;

    @Bean(name = "defaultKafkaStreamsConfig")
    public KafkaStreamsConfiguration defaultKafkaStreamsConfig() {
        Map<String, Object> props = new HashMap<>();
        props.put(org.apache.kafka.streams.StreamsConfig.APPLICATION_ID_CONFIG, applicationId);
        props.put(org.apache.kafka.streams.StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put("schema.registry.url", schemaRegistryUrl);
        props.put(org.apache.kafka.streams.StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, org.apache.kafka.common.serialization.Serdes.String().getClass().getName());
        props.put(org.apache.kafka.streams.StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, io.confluent.kafka.streams.serdes.avro.GenericAvroSerde.class);
        props.put(org.apache.kafka.streams.StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 1000);
        props.put(org.apache.kafka.streams.StreamsConfig.STATE_DIR_CONFIG, "/tmp/kafka-streams");
        props.put(org.apache.kafka.streams.StreamsConfig.NUM_STREAM_THREADS_CONFIG, 3);
        props.put(org.apache.kafka.streams.StreamsConfig.RECONNECT_BACKOFF_MS_CONFIG, 1000);
        props.put(org.apache.kafka.streams.StreamsConfig.RECONNECT_BACKOFF_MAX_MS_CONFIG, 10000);
        props.put(org.apache.kafka.streams.StreamsConfig.DEFAULT_TIMESTAMP_EXTRACTOR_CLASS_CONFIG, org.apache.kafka.streams.processor.WallclockTimestampExtractor.class.getName());
        return new KafkaStreamsConfiguration(props);
    }

    @Bean(name = "kafkaStreamsConfigTopic1")
    public KafkaStreamsConfiguration kafkaStreamsConfigTopic1() {
        Map<String, Object> props = new HashMap<>();
        props.put(org.apache.kafka.streams.StreamsConfig.APPLICATION_ID_CONFIG, applicationId + "-topic1");
        props.put(org.apache.kafka.streams.StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(org.apache.kafka.streams.StreamsConfig.GROUP_ID_CONFIG, groupIdTopic1);
        props.put("schema.registry.url", schemaRegistryUrl);
        props.put(org.apache.kafka.streams.StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, org.apache.kafka.common.serialization.Serdes.String().getClass().getName());
        props.put(org.apache.kafka.streams.StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, io.confluent.kafka.streams.serdes.avro.GenericAvroSerde.class);
        return new KafkaStreamsConfiguration(props);
    }

    @Bean(name = "kafkaStreamsConfigTopic2")
    public KafkaStreamsConfiguration kafkaStreamsConfigTopic2() {
        Map<String, Object> props = new HashMap<>();
        props.put(org.apache.kafka.streams.StreamsConfig.APPLICATION_ID_CONFIG, applicationId + "-topic2");
        props.put(org.apache.kafka.streams.StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(org.apache.kafka.streams.StreamsConfig.GROUP_ID_CONFIG, groupIdTopic2);
        props.put("schema.registry.url", schemaRegistryUrl);
        props.put(org.apache.kafka.streams.StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, org.apache.kafka.common.serialization.Serdes.String().getClass().getName());
        props.put(org.apache.kafka.streams.StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, io.confluent.kafka.streams.serdes.avro.GenericAvroSerde.class);
        return new KafkaStreamsConfiguration(props);
    }

    @Bean
    public KStream<String, GenericRecord> kStream1(StreamsBuilderFactoryBean streamsBuilderFactoryBean) {
        StreamsBuilder streamsBuilder = streamsBuilderFactoryBean.getObject();
        KStream<String, GenericRecord> stream = streamsBuilder.stream("topic1");
        return stream;
    }

    @Bean
    public KStream<String, GenericRecord> kStream2(StreamsBuilderFactoryBean streamsBuilderFactoryBean) {
        StreamsBuilder streamsBuilder = streamsBuilderFactoryBean.getObject();
        KStream<String, GenericRecord> stream = streamsBuilder.stream("topic2");
        return stream;
    }

    @Bean
    public KStream<String, String> joinedStream(StreamsBuilderFactoryBean streamsBuilderFactoryBean,
                                                KStream<String, GenericRecord> kStream1,
                                                KStream<String, GenericRecord> kStream2) {
        StreamsBuilder streamsBuilder = streamsBuilderFactoryBean.getObject();

        KStream<String, String> joinedStream = kStream1.join(
                kStream2,
                (value1, value2) -> value1.toString() + " joined with " + value2.toString(), // Join logic
                JoinWindows.of(Duration.ofMinutes(5)),
                StreamJoined.with(Serdes.String(), new GenericAvroSerde(), new GenericAvroSerde())
        );

        joinedStream.to("joined-topic", Produced.with(Serdes.String(), Serdes.String()));
        return joinedStream;
    }
}
-----
spring:
  kafka:
    bootstrap-servers: localhost:9092
    streams:
      application-id: kafka-cg-aggregator
      properties:
        schema.registry.url: http://localhost:8081
        default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        default.value.serde: io.confluent.kafka.streams.serdes.avro.GenericAvroSerde
        commit.interval.ms: 1000 # Frequency of commit in ms
        state.dir: /tmp/kafka-streams # Directory location for state store
        num.stream.threads: 3 # Number of stream threads in the application
        connection.max.idle.ms: 900000 # Adjusted max idle time for streams connections
        reconnect.backoff.ms: 1000 # Time to wait before attempting reconnection after disconnection
        reconnect.backoff.max.ms: 10000 # Maximum time to wait before attempting reconnection
        auto.offset.reset: latest

    consumer:
      auto-offset-reset: latest

    # Additional configurations for each topic group
    topic1:
      group-id: kafka-cg-aggregator-topic1
    topic2:
      group-id: kafka-cg-aggregator-topic2
